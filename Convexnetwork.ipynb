{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 14:47:10.637958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-14 14:47:10.732455: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-14 14:47:10.732470: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-14 14:47:11.289688: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-14 14:47:11.289726: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-14 14:47:11.289731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Layer \n",
    "computes whether input point is on the right side of the Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InHull(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=1): # one output\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        w_init=tf.random_normal_initializer()\n",
    "        nHplanes = input_shape[-1] + 1\n",
    "        nDims = input_shape[-1]\n",
    "        self.w = tf.Variable(initial_value = w_init(shape = (nHplanes, nDims),\n",
    "                                                    dtype=\"float32\"), \n",
    "                             trainable = True)\n",
    "        print(\"Weights in layer: \", self.w)\n",
    "        #print(\"length of layer: \", len(self.w)/2)\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(initial_value = b_init(shape = (nHplanes, nDims),\n",
    "                                                    dtype = \"float32\"), \n",
    "                             trainable = True)\n",
    "        print(\"Bias in Layer: \", self.b)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # print(\"weights:\", self.w)\n",
    "        # print(\"biases:\", self.b)\n",
    "        # print(\"inputs:\", inputs)\n",
    "        # ntpoint = inputs\n",
    "        # point = np.transpose(ntpoint)\n",
    "        # print(\"point:\", point)\n",
    "        # dots = [K.sum(self.w[i] * (self.b[i] - point), axis = -1, keepdims = True) for i in range(4)]#range(len(self.w)/2)]\n",
    "        # print(\"dots\", dots)\n",
    "        res = K.sum(self.w[0] * (self.w[1] - inputs), axis = -1, keepdims = True)\n",
    "        # print(\"here=\", res)\n",
    "        # print(res)\n",
    "        #return tf.Variable[0.0]\n",
    "        return K.sum(self.w[0] * (self.w[1] - inputs), axis = -1, keepdims = True)\n",
    "        # return K.batch_dot(inputs * self.w, axis =-1,keepdims = True) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.]\n",
      " [ 1.  1.  1.]\n",
      " [-1. -1. -1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "Weights in layer:  <tf.Variable 'in_hull_27/Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
      "array([[ 0.01864201, -0.05431065,  0.09596236],\n",
      "       [-0.05934132,  0.02205252,  0.03555093],\n",
      "       [-0.03432096, -0.01854827,  0.09575459],\n",
      "       [-0.01217742,  0.06513804, -0.05324098]], dtype=float32)>\n",
      "Bias in Layer:  <tf.Variable 'in_hull_27/Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
      "array([[0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.]], dtype=float32)>\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['in_hull_27/Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['in_hull_27/Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['in_hull_27/Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['in_hull_27/Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    }
   ],
   "source": [
    "def in_convex_hull(point, plane_point, plane_normal):\n",
    "    if np.dot(plane, (point - a)) == 1:\n",
    "        return true\n",
    "    return false\n",
    "\n",
    "def custom_loss(actual, pred):\n",
    "    loss = 0\n",
    "    return loss\n",
    "\n",
    "model = keras.Sequential([InHull(1)])\n",
    "model.compile(optimizer='Adam', loss='BinaryCrossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "xs = np.array([[ 0.0, 0.0, 0.0],\n",
    "               [ 1.0, 1.0, 1.0],\n",
    "               [-1.0,-1.0,-1.0],\n",
    "               [ 1.0, 0.0, 0.0],\n",
    "               [ 0.0, 1.0, 0.0],\n",
    "               [ 0.0, 0.0, 1.0]])\n",
    "ys = np.array([[1],\n",
    "               [0],\n",
    "               [0],\n",
    "               [0],\n",
    "               [0],\n",
    "               [0]])\n",
    "\n",
    "# xs = np.array([[ 0.0, 0.0, 0.0]])\n",
    "# ys = np.array([[1]])\n",
    "\n",
    "history = model.fit(xs, ys, epochs=10000, batch_size=1, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00564666]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.array([[ 0.0, 0.0, 0.0]])\n",
    "\n",
    "model.predict(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  [[ 0.04484339 -0.01542579  0.01255676]\n",
      " [ 0.02095187  0.01758021 -0.02743695]\n",
      " [-0.02538426  0.02119865  0.0322537 ]\n",
      " [-0.01514442  0.06497443 -0.01204634]]\n",
      "Biases:  [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights: \", model.layers[0].get_weights()[0])\n",
    "print(\"Biases: \", model.layers[0].get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
      "array([[-0.02217364,  0.02388768, -0.01642606],\n",
      "       [ 0.0470141 , -0.1108605 ,  0.06211011],\n",
      "       [ 0.00317579,  0.00729559,  0.13069701],\n",
      "       [-0.0888112 ,  0.11896175, -0.07816519]], dtype=float32)> <tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
      "array([[1., 1., 1.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.]], dtype=float32)> <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>\n",
      "stop\n",
      "tf.Tensor([False], shape=(1,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "weight = tf.Variable([[-0.02217364,  0.02388768, -0.01642606],\n",
    "       [ 0.0470141 , -0.1108605 ,  0.06211011],\n",
    "       [ 0.00317579,  0.00729559,  0.13069701],\n",
    "       [-0.0888112 ,  0.11896175, -0.07816519]])\n",
    "bias = tf.Variable([[1., 1., 1.],\n",
    "       [0., 0., 0.],\n",
    "       [0., 0., 0.],\n",
    "       [0., 0., 0.]])\n",
    "input = tf.Variable([0.0,0.0,0.0])\n",
    "point = input\n",
    "print(weight, bias, point)\n",
    "print(\"stop\")\n",
    "dots = tf.Variable([K.sum(weight[i] * (bias[i] - point), axis = -1, keepdims = True) for i in range(4)])#range(len(self.w)/2)]\n",
    "# dots = dots/dots\n",
    "print(dots[1] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88724768 0.7934657  0.6324761 ]\n",
      " [0.83078754 0.44004283 0.635758  ]\n",
      " [0.33647652 0.92324053 0.86827978]\n",
      " ...\n",
      " [0.18818799 0.73330666 0.39180892]\n",
      " [0.98370983 0.93480106 0.39973269]\n",
      " [0.12962338 0.76257981 0.94893442]]\n"
     ]
    }
   ],
   "source": [
    "xs = np.array([np.random.rand(1000,3) for i in range(1)])[0]\n",
    "print(xs)\n",
    "xy = np.array( for x in xs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('convexgating')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4563856c7e00c136b2f0bc8bd3f700cb142f11a70aad1c3bfb1747bfd95dcf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
