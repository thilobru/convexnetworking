{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punkte in nD Erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "size = 1000\n",
    "n_dim = 3\n",
    "\n",
    "df = pd.DataFrame(2 * (np.random.rand(size, n_dim) - .5))\n",
    "df.columns = [\"x\", \"y\", \"z\"]\n",
    "\n",
    "def comp(row):\n",
    "    if abs(row[\"x\"]) + abs(row[\"y\"]) + abs(row[\"z\"]) >= 1:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "df['group'] = df.apply(lambda row: comp(row), axis = 1)\n",
    "\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize = (12,9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for grp_name, grp_idx in df.groupby('group').groups.items():\n",
    "    x = df.iloc[grp_idx,0]\n",
    "    y = df.iloc[grp_idx,1]\n",
    "    z = df.iloc[grp_idx,2]\n",
    "    ax.scatter(x,y,z, label=grp_name)  # this way you can control color/marker/size of each group freely\n",
    "    #ax.scatter(*df.iloc[grp_idx, [0, 1, 2]].T.values, label=grp_name)  # if you want to do everything in one line, lol\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planes erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes = [[[0,0,0],[1,0,0]],\n",
    "          [[0,0,0],[0,1,0]],\n",
    "          [[0,0,0],[0,0,1]],\n",
    "          [[5,5,5],[1,1,1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#fig = plt.figure(figsize=(12, 9)).gca(projection='3d')\n",
    "\n",
    "fig = plt.figure(figsize = (12,9))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "    \n",
    "for each in planes:\n",
    "    print(each)\n",
    "    point  = np.array(each[0])\n",
    "    normal = np.array(each[1])\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    # a plane is a*x+b*y+c*z+d=0\n",
    "    # [a,b,c] is the normal. Thus, we have to calculate\n",
    "    # d and we're set\n",
    "    d = -point.dot(normal)\n",
    "    # create x,y\n",
    "    xx,yy = np.meshgrid(range(10), range(10))\n",
    "    # calculate corresponding z\n",
    "    z = (-normal[0] * xx - normal[1] * yy - d) * 1. / (normal[2]+0.00000001)\n",
    "    # plot the surface\n",
    "    ax.plot_wireframe(xx, yy, z)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to build a Convex Hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n dimension we need n + 1 Hyperplanes to build a convex Hull encompassing points\n",
    "\n",
    "# planes = []\n",
    "\n",
    "# for i in range n_dim + 1:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for calculating 2 orhtogonal vectors for a given vector https://stackoverflow.com/questions/33658620/generating-two-orthogonal-vectors-that-are-orthogonal-to-a-particular-direction\n",
    "\n",
    "for determining if Point is to the right of a plane defined by a nromal vecotr https://qr.ae/pvgYcL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find 2 orthogonal vectors\n",
    "# plane = np.array(plane)\n",
    "# # find first orthogonal vector:\n",
    "# x = np.random.randn(3)          # take a random vector\n",
    "# x -= x.dot(plane) * plane       # make it orthogonal to k\n",
    "# x /= np.linalg.norm(x)          # normalize it\n",
    "# # find second orthogonal vector\n",
    "# y = np.cross(plane, x)          # cross product with k\n",
    "# print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate if P is in the half space that v points into from point A on the plane that divides the space\n",
    "a = np.array([0,0,0])\n",
    "plane = np.array([0,0,0])\n",
    "point = np.array([-1,0,0])\n",
    "np.dot(plane, (point - a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/thilo/Documents/convexnetworking/network.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/thilo/Documents/convexnetworking/network.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m,random_state\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thilo/Documents/convexnetworking/network.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test  \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(train\u001b[39m.\u001b[39mindex)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thilo/Documents/convexnetworking/network.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thilo/Documents/convexnetworking/network.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mpoint\u001b[39m\u001b[39m\"\u001b[39m: train[[\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mz\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thilo/Documents/convexnetworking/network.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: train[[\u001b[39m\"\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thilo/Documents/convexnetworking/network.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "train = df.sample(frac=0.8,random_state=200)\n",
    "test  = df.drop(train.index)\n",
    "\n",
    "train_df = pd.DataFrame({\n",
    "            \"point\": train[[\"x\",\"y\",\"z\"]].values.tolist(),\n",
    "            \"label\": train[[\"group\"]].values.tolist()\n",
    "        })\n",
    "\n",
    "train_points = np.array([np.array(x) for x in train_df[\"point\"].values.tolist()])\n",
    "train_labels = np.array(train_df[\"label\"].values.tolist())\n",
    "\n",
    "train_ds = [train_points, train_labels]\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "            \"point\": test[[\"x\",\"y\",\"z\"]].values.tolist(),\n",
    "            \"label\": test[[\"group\"]].values.tolist()\n",
    "        })\n",
    "\n",
    "test_points = np.array([np.array(x) for x in test_df[\"point\"].values.tolist()])\n",
    "test_labels = np.array(test_df[\"label\"].values.tolist())\n",
    "\n",
    "test_ds = [test_points, test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InHull(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=1): # one output\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        w_init=tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(initial_value = w_init(shape = (4,input_shape[-1]),\n",
    "                                                    dtype=\"float32\"), \n",
    "                             trainable = True)\n",
    "        print(\"Weights in layer: \", self.w)\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(initial_value = b_init(shape = (self.units,),dtype = \"float32\"), trainable = True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return K.sum(self.w[0] * (self.w[1] - inputs), axis = -1, keepdims = True)\n",
    "        # return K.batch_dot(inputs * self.w, axis =-1,keepdims = True) + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([6. 5. 5.], shape=(3,), dtype=float32) tf.Tensor(\n",
      "[[5. 5. 5.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "-1.0 tf.Tensor([-1.], shape=(1,), dtype=float32)\n",
      "Weights in layer:  <tf.Variable 'in_hull_28/Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[-0.00175405, -0.09278544, -0.00449148],\n",
      "       [ 0.05843281,  0.01407873,  0.05551393]], dtype=float32)>\n",
      "The Layer predicted:  tf.Tensor([0.49525076], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([6,5,5], dtype = \"float32\")\n",
    "plane = tf.constant([[5, 5, 5], [1, 1, 1]], dtype = \"float32\")\n",
    "print(x, plane)\n",
    "# C = K.sum(x * plane[0], axis = 0)#, keepdims = True)\n",
    "\n",
    "trueResult = np.dot(plane[1], (plane[0] - x))\n",
    "C = K.sum(plane[1] * (plane[0] - x), axis = 0, keepdims = True)\n",
    "print(trueResult, C)\n",
    "\n",
    "linear_layer = InHull(1)\n",
    "y = linear_layer(x)\n",
    "print(\"The Layer predicted: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Weights in layer:  <tf.Variable 'in_hull_27/Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[-0.0503907 ,  0.02165143, -0.00509985],\n",
      "       [ 0.00870017,  0.04483277, -0.0709506 ]], dtype=float32)>\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['in_hull_27/Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['in_hull_27/Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['in_hull_27/Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['in_hull_27/Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9204 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7182 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5584 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4245 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2765 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1369 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9864 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8104 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: -0.0545 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def in_convex_hull(point, plane_point, plane_normal):\n",
    "    if np.dot(plane, (point - a)) == 1:\n",
    "        return true\n",
    "    return false\n",
    "\n",
    "def custom_loss(actual, pred):\n",
    "    loss = 0\n",
    "    return loss\n",
    "\n",
    "model = keras.Sequential([InHull(1)])\n",
    "# model.add(keras.layers.Dense(1000))\n",
    "# model.add(keras.layers.Dense(24))\n",
    "model.compile(optimizer='Adam', loss='BinaryCrossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "xs = np.array([[0.0, 0.0, 0.0],\n",
    "               [1.0, 1.0, 1.0]])\n",
    "ys = np.array([[1],\n",
    "               [-1]])\n",
    "\n",
    "history = model.fit(xs, ys, epochs=10, batch_size=1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 8.5176 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5313 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2507 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0150 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7952 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.5391 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3024 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.0377 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.7690 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.5112 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def in_convex_hull(point, plane_point, plane_normal):\n",
    "    if np.dot(plane, (point - a)) == 1:\n",
    "        return true\n",
    "    return false\n",
    "\n",
    "def custom_loss(actual, pred):\n",
    "    loss = 0\n",
    "    return loss\n",
    "def custom_layer():\n",
    "    return\n",
    "\n",
    "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[800,3])])\n",
    "model.add(keras.layers.Dense(1000))\n",
    "model.add(keras.layers.Dense(24))\n",
    "model.compile(optimizer='Adam', loss='BinaryCrossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "xs = train_points\n",
    "xs = np.array([np.random.rand(800,3) for i in range(1)])\n",
    "\n",
    "ys = np.array([train_labels])\n",
    "\n",
    "history = model.fit(xs, ys, epochs=10, batch_size=1, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.5344727039337158,\n",
       "  0.5439260601997375,\n",
       "  0.505598247051239,\n",
       "  0.4892033636569977,\n",
       "  0.49211326241493225,\n",
       "  0.4920598566532135,\n",
       "  0.4919050335884094,\n",
       "  0.4918493926525116,\n",
       "  0.49421292543411255,\n",
       "  0.4926723539829254]}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 12:56:35.954072: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-07 12:56:36.053124: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-07 12:56:36.053137: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-07 12:56:36.597270: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 12:56:36.597314: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 12:56:36.597319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "#for n dimensions we have \n",
    "# Points defined by n numbers\n",
    "# n + 1 Planes that cut the space R defined by each\n",
    "#   # 1 normal vector\n",
    "#   # 1 Point on the plane\n",
    "# normal vector and point are to be optimized such that\n",
    "# most number of points are within convex hull that is surrounding them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                128       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 392\n",
      "Trainable params: 392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 12:56:37.470587: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-07 12:56:37.470600: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-07 12:56:37.470630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (thilo-HP-ProDesk-600-G6-Microtower-PC): /proc/driver/nvidia/version does not exist\n",
      "2022-12-07 12:56:37.470783: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Create a `Sequential` model and add a Dense layer as the first layer.\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(3,)))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "# Now the model will take as input arrays of shape (None, 3)\n",
    "# and output arrays of shape (None, 32).\n",
    "# Note that after the first layer, you don't need to specify\n",
    "# the size of the input anymore:\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "model.output_shape\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an optimizer and loss function for training: \n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# Select metrics to measure the loss and the accuracy of the model. \n",
    "# These metrics accumulate the values over epochs and then print the overall result.\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.GradientTape to train the model:\n",
    "@tf.function\n",
    "def train_step(points, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(points, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)\n",
    "# Test the model:\n",
    "@tf.function\n",
    "def test_step(points, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(points, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (3,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_278695/1084042546.py\", line 7, in train_step  *\n        predictions = model(points, training=True)\n    File \"/home/thilo/miniconda3/envs/convexgating/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/thilo/miniconda3/envs/convexgating/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (3,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(3,), dtype=float64)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/thilo/Documents/convexnetworking/network.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thilo/Documents/convexnetworking/network.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m test_accuracy\u001b[39m.\u001b[39mreset_states()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thilo/Documents/convexnetworking/network.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m train_ds:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/thilo/Documents/convexnetworking/network.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m   train_step(np\u001b[39m.\u001b[39;49marray(images), labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thilo/Documents/convexnetworking/network.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m test_images, test_labels \u001b[39min\u001b[39;00m test_ds:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/thilo/Documents/convexnetworking/network.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   test_step(test_images, test_labels)\n",
      "File \u001b[0;32m~/miniconda3/envs/convexgating/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file435blwnk.py:9\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(points, labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mFunctionScope(\u001b[39m'\u001b[39m\u001b[39mtrain_step\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfscope\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mConversionOptions(recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, user_requested\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, optional_features\u001b[39m=\u001b[39m(), internal_convert_user_code\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)) \u001b[39mas\u001b[39;00m fscope:\n\u001b[1;32m      8\u001b[0m     \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m----> 9\u001b[0m         predictions \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(model), (ag__\u001b[39m.\u001b[39mld(points),), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)\n\u001b[1;32m     10\u001b[0m         loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(loss_object), (ag__\u001b[39m.\u001b[39mld(labels), ag__\u001b[39m.\u001b[39mld(predictions)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m     gradients \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mgradient, (ag__\u001b[39m.\u001b[39mld(loss), ag__\u001b[39m.\u001b[39mld(model)\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/miniconda3/envs/convexgating/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/convexgating/lib/python3.8/site-packages/keras/engine/input_spec.py:250\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    248\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 250\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m         )\n\u001b[1;32m    257\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_278695/1084042546.py\", line 7, in train_step  *\n        predictions = model(points, training=True)\n    File \"/home/thilo/miniconda3/envs/convexgating/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/thilo/miniconda3/envs/convexgating/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 250, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (3,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(3,), dtype=float64)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "\n",
    "  for images, labels in train_ds:\n",
    "    train_step(np.array(images), labels)\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Loss: {test_loss.result()}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('convexgating')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4563856c7e00c136b2f0bc8bd3f700cb142f11a70aad1c3bfb1747bfd95dcf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
